use crate::{
    cache::get_cached_config,
    types::*,
    utils::{extract_tool_call_id, filter_tools_for_poe, get_text_from_openai_content},
};
use futures_util::Stream;
use poe_api_process::types::Attachment;
use poe_api_process::{ChatMessage, ChatRequest, ChatResponse, PoeClient, PoeError};
use std::pin::Pin;
use std::sync::Arc;
use std::time::Instant;
use tracing::{debug, error, info};

pub struct PoeClientWrapper {
    pub client: PoeClient, // ä¿®æ”¹ç‚ºå…¬é–‹ï¼Œä»¥ä¾¿å¤–éƒ¨è¨ªå•
    _model: String,
}

impl PoeClientWrapper {
    pub fn new(model: &str, access_key: &str) -> Self {
        info!("ğŸ”‘ åˆå§‹åŒ– POE å®¢æˆ¶ç«¯ | æ¨¡å‹: {}", model);

        // å¾ç’°å¢ƒè®Šæ•¸ç²å– POE API é…ç½®ï¼Œä½¿ç”¨é è¨­å€¼
        let poe_base_url =
            std::env::var("POE_BASE_URL").unwrap_or_else(|_| "https://api.poe.com".to_string());
        let poe_file_upload_url = std::env::var("POE_FILE_UPLOAD_URL").unwrap_or_else(|_| {
            "https://www.quora.com/poe_api/file_upload_3RD_PARTY_POST".to_string()
        });

        debug!(
            "ğŸ”§ POE é…ç½® | Base URL: {} | Upload URL: {}",
            poe_base_url, poe_file_upload_url
        );

        Self {
            client: PoeClient::new(model, access_key, &poe_base_url, &poe_file_upload_url),
            _model: model.to_string(),
        }
    }

    /// ç²å– v1/models API çš„æ¨¡å‹åˆ—è¡¨
    pub async fn get_v1_model_list(
        &self,
    ) -> Result<poe_api_process::ModelResponse, poe_api_process::PoeError> {
        let start_time = std::time::Instant::now();
        debug!("ğŸ“‹ ç™¼é€ v1/models API è«‹æ±‚");

        let result = self.client.get_v1_model_list().await;

        match &result {
            Ok(model_response) => {
                let duration = start_time.elapsed();
                info!(
                    "âœ… v1/models API è«‹æ±‚æˆåŠŸ | æ¨¡å‹æ•¸é‡: {} | è€—æ™‚: {}",
                    model_response.data.len(),
                    crate::utils::format_duration(duration)
                );
            }
            Err(e) => {
                let duration = start_time.elapsed();
                error!(
                    "âŒ v1/models API è«‹æ±‚å¤±æ•— | éŒ¯èª¤: {} | è€—æ™‚: {}",
                    e,
                    crate::utils::format_duration(duration)
                );
            }
        }

        result
    }

    pub async fn stream_request(
        &self,
        chat_request: ChatRequest,
    ) -> Result<Pin<Box<dyn Stream<Item = Result<ChatResponse, PoeError>> + Send>>, PoeError> {
        let start_time = Instant::now();
        debug!(
            "ğŸ“¤ ç™¼é€ä¸²æµè«‹æ±‚ | è¨Šæ¯æ•¸é‡: {} | æº«åº¦è¨­ç½®: {:?}",
            chat_request.query.len(),
            chat_request.temperature
        );
        let result = self.client.stream_request(chat_request).await;
        match &result {
            Ok(_) => {
                let duration = start_time.elapsed();
                info!(
                    "âœ… ä¸²æµè«‹æ±‚å»ºç«‹æˆåŠŸ | è€—æ™‚: {}",
                    crate::utils::format_duration(duration)
                );
            }
            Err(e) => {
                let duration = start_time.elapsed();
                error!(
                    "âŒ ä¸²æµè«‹æ±‚å¤±æ•— | éŒ¯èª¤: {} | è€—æ™‚: {}",
                    e,
                    crate::utils::format_duration(duration)
                );
            }
        }
        result
    }
}

// OpenAI æ¶ˆæ¯æ ¼å¼è½‰æ›ç‚º Poe æ¶ˆæ¯æ ¼å¼çš„å‡½æ•¸
fn openai_message_to_poe(
    msg: &Message,
    role_override: Option<String>,
    chat_completion_request: Option<&ChatCompletionRequest>,
) -> ChatMessage {
    let mut attachments: Vec<Attachment> = vec![];
    let mut texts: Vec<String> = vec![];

    // è™•ç† content æ¬„ä½
    if let Some(content) = &msg.content {
        match content {
            OpenAiContent::Text(s) => {
                texts.push(s.clone());
            }
            OpenAiContent::Multi(arr) => {
                for item in arr {
                    match item {
                        OpenAiContentItem::Text { text } => texts.push(text.clone()),
                        OpenAiContentItem::ImageUrl { image_url } => {
                            debug!("ğŸ–¼ï¸  è™•ç†åœ–ç‰‡ URL: {}", image_url.url);
                            attachments.push(Attachment {
                                url: image_url.url.clone(),
                                content_type: None,
                            });
                        }
                    }
                }
            }
        }
    }

    // è™•ç† tool_callsï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if let Some(tool_calls) = &msg.tool_calls {
        debug!(
            "ğŸ”§ è™•ç† assistant æ¶ˆæ¯ä¸­çš„ tool_callsï¼Œæ•¸é‡: {}",
            tool_calls.len()
        );
        // å°‡ tool_calls è½‰æ›ç‚ºæ–‡æœ¬æ ¼å¼æ·»åŠ åˆ°å…§å®¹ä¸­
        for tool_call in tool_calls {
            let tool_call_text = format!(
                "Tool Call: {} ({})\nArguments: {}",
                tool_call.function.name, tool_call.id, tool_call.function.arguments
            );
            texts.push(tool_call_text);
        }
    }

    // è™•ç† tool_call_id
    if let Some(tool_call_id) = &msg.tool_call_id {
        debug!("ğŸ”§ è™•ç† tool æ¶ˆæ¯ä¸­çš„ tool_call_id: {}", tool_call_id);
        // å°‡ tool_call_id æ·»åŠ åˆ°å…§å®¹é–‹é ­
        let tool_id_text = format!("Tool Call ID: {}", tool_call_id);
        texts.insert(0, tool_id_text);
    }

    let mut content = texts.join("\n");

    // å¦‚æœæ˜¯ç”¨æˆ¶æ¶ˆæ¯ä¸”æ˜¯æœ€å¾Œä¸€æ¢æ¶ˆæ¯ï¼Œæ‡‰ç”¨å¾Œç¶´è™•ç†
    if msg.role == "user" {
        if let Some(request) = chat_completion_request {
            content = crate::utils::process_message_content_with_suffixes(&content, request);
        }
    }

    let role = role_override.unwrap_or_else(|| msg.role.clone());
    ChatMessage {
        role,
        content,
        attachments: if !attachments.is_empty() {
            debug!("ğŸ“ æ·»åŠ  {} å€‹é™„ä»¶åˆ°æ¶ˆæ¯", attachments.len());
            Some(attachments)
        } else {
            None
        },
        content_type: "text/markdown".to_string(),
    }
}

pub async fn create_chat_request(
    model: &str,
    messages: Vec<Message>,
    chat_completion_request: &ChatCompletionRequest,
) -> ChatRequest {
    let temperature = chat_completion_request.temperature;
    let original_tools = chat_completion_request.tools.clone();
    let tools = filter_tools_for_poe(&original_tools);
    let logit_bias = chat_completion_request.logit_bias.clone();
    let stop = chat_completion_request.stop.clone();

    debug!(
        "ğŸ“ å‰µå»ºèŠå¤©è«‹æ±‚ | æ¨¡å‹: {} | è¨Šæ¯æ•¸é‡: {} | æº«åº¦è¨­ç½®: {:?} | åŸå§‹å·¥å…·æ•¸é‡: {:?} | éæ¿¾å¾Œå·¥å…·æ•¸é‡: {:?}",
        model,
        messages.len(),
        temperature,
        original_tools.as_ref().map(|t| t.len()),
        tools.as_ref().map(|t| t.len())
    );
    // å¾ç·©å­˜ç²å– models.yaml é…ç½®
    let config: Arc<Config> = get_cached_config().await;
    // æª¢æŸ¥æ¨¡å‹æ˜¯å¦éœ€è¦ replace_response è™•ç†
    let should_replace_response = if let Some(model_config) = config.models.get(model) {
        // ä½¿ç”¨å¿«å–çš„ config
        model_config.replace_response.unwrap_or(false)
    } else {
        false
    };
    debug!(
        "ğŸ” æ¨¡å‹ {} çš„ replace_response è¨­ç½®: {}",
        model, should_replace_response
    );
    let query = messages
        .iter()
        .enumerate()
        .map(|(index, msg)| {
            let original_role = &msg.role;
            let role_override = match original_role.as_str() {
                // ç¸½æ˜¯å°‡ assistant è½‰æ›ç‚º bot
                "assistant" => Some("bot".to_string()),
                // ç¸½æ˜¯å°‡ developer è½‰æ›ç‚º user
                "developer" => Some("user".to_string()),
                // ç¸½æ˜¯å°‡ tool è½‰æ›ç‚º user
                "tool" => Some("user".to_string()),
                // åªæœ‰åœ¨ replace_response ç‚º true æ™‚æ‰è½‰æ› system ç‚º user
                "system" if should_replace_response => Some("user".to_string()),
                // å…¶ä»–æƒ…æ³ä¿æŒåŸæ¨£
                _ => None,
            };
            // å°‡ OpenAI æ¶ˆæ¯è½‰æ›ç‚º Poe æ¶ˆæ¯
            // åªå°æœ€å¾Œä¸€æ¢ç”¨æˆ¶æ¶ˆæ¯æ‡‰ç”¨å¾Œç¶´è™•ç†
            let is_last_user_message = msg.role == "user" && index == messages.len() - 1;
            let request_param = if is_last_user_message {
                Some(chat_completion_request)
            } else {
                None
            };
            let poe_message = openai_message_to_poe(msg, role_override, request_param);
            // ç´€éŒ„è½‰æ›çµæœ
            debug!(
                "ğŸ”„ è™•ç†è¨Šæ¯ | åŸå§‹è§’è‰²: {} | è½‰æ›å¾Œè§’è‰²: {} | å…§å®¹é•·åº¦: {} | é™„ä»¶æ•¸é‡: {}",
                original_role,
                poe_message.role,
                crate::utils::format_bytes_length(poe_message.content.len()),
                poe_message.attachments.as_ref().map_or(0, |a| a.len())
            );
            poe_message
        })
        .collect();

    // è™•ç†å·¥å…·çµæœæ¶ˆæ¯
    let mut tool_results = None;
    // æª¢æŸ¥æ˜¯å¦æœ‰ tool è§’è‰²çš„æ¶ˆæ¯ï¼Œä¸¦å°‡å…¶è½‰æ›ç‚º ToolResult
    if messages.iter().any(|msg| msg.role == "tool") {
        // é¦–å…ˆå»ºç«‹ tool_call_id åˆ°å·¥å…·åç¨±çš„æ˜ å°„
        let mut tool_call_id_to_name: std::collections::HashMap<String, String> = std::collections::HashMap::new();
        
        // å¾ä¹‹å‰çš„ assistant æ¶ˆæ¯ä¸­æå–å·¥å…·èª¿ç”¨ä¿¡æ¯
        for msg in &messages {
            if msg.role == "assistant" {
                if let Some(tool_calls) = &msg.tool_calls {
                    for tool_call in tool_calls {
                        tool_call_id_to_name.insert(tool_call.id.clone(), tool_call.function.name.clone());
                        debug!("ğŸ”§ æ˜ å°„å·¥å…·èª¿ç”¨ | ID: {} | åç¨±: {}", tool_call.id, tool_call.function.name);
                    }
                }
            }
        }
        
        let mut results = Vec::new();
        for msg in messages {
            if msg.role == "tool" {
                // å„ªå…ˆä½¿ç”¨æ–°çš„ tool_call_id æ¬„ä½
                let tool_call_id = if let Some(id) = &msg.tool_call_id {
                    id.clone()
                } else {
                    // å¦‚æœæ²’æœ‰ tool_call_id æ¬„ä½ï¼Œå˜—è©¦å¾å…§å®¹ä¸­æå–
                    let content_text = get_text_from_openai_content(&msg.content);
                    if let Some(id) = extract_tool_call_id(&content_text) {
                        id
                    } else {
                        debug!("âš ï¸ ç„¡æ³•å¾å·¥å…·æ¶ˆæ¯ä¸­æå– tool_call_id");
                        continue;
                    }
                };

                // å¾æ˜ å°„ä¸­æŸ¥æ‰¾å·¥å…·åç¨±ï¼Œå¦‚æœæ‰¾ä¸åˆ°å‰‡ä½¿ç”¨ "unknown"
                let tool_name = tool_call_id_to_name.get(&tool_call_id)
                    .cloned()
                    .unwrap_or_else(|| {
                        debug!("âš ï¸ ç„¡æ³•æ‰¾åˆ° tool_call_id {} å°æ‡‰çš„å·¥å…·åç¨±ï¼Œä½¿ç”¨ unknown", tool_call_id);
                        "unknown".to_string()
                    });

                let content_text = get_text_from_openai_content(&msg.content);
                debug!("ğŸ”§ è™•ç†å·¥å…·çµæœ | tool_call_id: {} | å·¥å…·åç¨±: {}", tool_call_id, tool_name);
                results.push(poe_api_process::types::ChatToolResult {
                    role: "tool".to_string(),
                    tool_call_id,
                    name: tool_name,
                    content: content_text,
                });
            }
        }
        if !results.is_empty() {
            tool_results = Some(results);
            debug!(
                "ğŸ”§ å‰µå»ºäº† {} å€‹å·¥å…·çµæœ",
                tool_results.as_ref().unwrap().len()
            );
        }
    }
    ChatRequest {
        version: "1.1".to_string(),
        r#type: "query".to_string(),
        query,
        temperature,
        user_id: "".to_string(),
        conversation_id: "".to_string(),
        message_id: "".to_string(),
        tools,
        tool_calls: None,
        tool_results,
        logit_bias,
        stop_sequences: stop,
    }
}
