use crate::cache::get_cached_config;
use crate::evert::{EventContext, EventHandlerManager};
use crate::poe_client::{PoeClientWrapper, create_chat_request};
use crate::types::*;
use crate::utils::{
    convert_poe_error_to_openai, count_completion_tokens, count_message_tokens,
    format_bytes_length, format_duration, process_message_images,
};
use chrono::Utc;
use futures_util::future::{self};
use futures_util::stream::{self, Stream, StreamExt};
use nanoid::nanoid;
use poe_api_process::ChatResponseData;
use poe_api_process::{ChatEventType, ChatResponse, PoeError};
use salvo::http::header;
use salvo::prelude::*;
use serde_json::json;
use std::collections::HashMap;
use std::pin::Pin;
use std::sync::{Arc, Mutex};
use std::time::Instant;
use tracing::{debug, error, info, warn};

#[handler]
pub async fn chat_completions(req: &mut Request, res: &mut Response) {
    let start_time = Instant::now();
    info!("ğŸ“ æ”¶åˆ°æ–°çš„èŠå¤©å®Œæˆè«‹æ±‚");

    let max_size: usize = std::env::var("MAX_REQUEST_SIZE")
        .unwrap_or_else(|_| "1073741824".to_string())
        .parse()
        .unwrap_or(1024 * 1024 * 1024);

    // å¾ç·©å­˜ç²å– models.yaml é…ç½®
    let config = get_cached_config().await;
    debug!("ğŸ”§ å¾ç·©å­˜ç²å–é…ç½® | å•Ÿç”¨ç‹€æ…‹: {:?}", config.enable);

    // é©—è­‰æˆæ¬Š
    let access_key = match req.headers().get("Authorization") {
        Some(auth) => {
            let auth_str = auth.to_str().unwrap_or("");
            if let Some(stripped) = auth_str.strip_prefix("Bearer ") {
                debug!("ğŸ”‘ é©—è­‰ä»¤ç‰Œé•·åº¦: {}", stripped.len());
                stripped.to_string()
            } else {
                error!("âŒ ç„¡æ•ˆçš„æˆæ¬Šæ ¼å¼");
                res.status_code(StatusCode::UNAUTHORIZED);
                res.render(Json(json!({ "error": "ç„¡æ•ˆçš„ Authorization" })));
                return;
            }
        }
        None => {
            error!("âŒ ç¼ºå°‘æˆæ¬Šæ¨™é ­");
            res.status_code(StatusCode::UNAUTHORIZED);
            res.render(Json(json!({ "error": "ç¼ºå°‘ Authorization" })));
            return;
        }
    };

    // è§£æè«‹æ±‚é«”
    let chat_request = match req.payload_with_max_size(max_size).await {
        Ok(bytes) => match serde_json::from_slice::<ChatCompletionRequest>(bytes) {
            Ok(req) => {
                debug!(
                    "ğŸ“Š è«‹æ±‚è§£ææˆåŠŸ | æ¨¡å‹: {} | è¨Šæ¯æ•¸é‡: {} | æ˜¯å¦ä¸²æµ: {:?}",
                    req.model,
                    req.messages.len(),
                    req.stream
                );
                req
            }
            Err(e) => {
                error!("âŒ JSON è§£æå¤±æ•—: {}", e);
                res.status_code(StatusCode::BAD_REQUEST);
                res.render(Json(OpenAIErrorResponse {
                    error: OpenAIError {
                        message: format!("JSON è§£æå¤±æ•—: {}", e),
                        r#type: "invalid_request_error".to_string(),
                        code: "parse_error".to_string(),
                        param: None,
                    },
                }));
                return;
            }
        },
        Err(e) => {
            error!("âŒ è«‹æ±‚å¤§å°è¶…éé™åˆ¶æˆ–è®€å–å¤±æ•—: {}", e);
            res.status_code(StatusCode::PAYLOAD_TOO_LARGE);
            res.render(Json(OpenAIErrorResponse {
                error: OpenAIError {
                    message: format!("è«‹æ±‚å¤§å°è¶…éé™åˆ¶ ({} bytes) æˆ–è®€å–å¤±æ•—: {}", max_size, e),
                    r#type: "invalid_request_error".to_string(),
                    code: "payload_too_large".to_string(),
                    param: None,
                },
            }));
            return;
        }
    };

    // å°‹æ‰¾æ˜ å°„çš„åŸå§‹æ¨¡å‹åç¨±
    let (display_model, original_model) = if config.enable.unwrap_or(false) {
        let requested_model = chat_request.model.clone();
        // æª¢æŸ¥ç•¶å‰è«‹æ±‚çš„æ¨¡å‹æ˜¯å¦æ˜¯æŸå€‹æ˜ å°„çš„ç›®æ¨™
        let mapping_entry = config.models.iter().find(|(_, cfg)| {
            if let Some(mapping) = &cfg.mapping {
                mapping.to_lowercase() == requested_model.to_lowercase()
            } else {
                false
            }
        });
        if let Some((original_name, _)) = mapping_entry {
            // å¦‚æœæ‰¾åˆ°æ˜ å°„ï¼Œä½¿ç”¨åŸå§‹æ¨¡å‹åç¨±
            debug!("ğŸ”„ åå‘æ¨¡å‹æ˜ å°„: {} -> {}", requested_model, original_name);
            (requested_model, original_name.clone())
        } else {
            // å¦‚æœæ²’æ‰¾åˆ°æ˜ å°„ï¼Œæª¢æŸ¥æ˜¯å¦æœ‰ç›´æ¥æ˜ å°„é…ç½®
            if let Some(model_config) = config.models.get(&requested_model) {
                if let Some(mapped_name) = &model_config.mapping {
                    debug!("ğŸ”„ ç›´æ¥æ¨¡å‹æ˜ å°„: {} -> {}", requested_model, mapped_name);
                    (requested_model.clone(), requested_model)
                } else {
                    // æ²’æœ‰æ˜ å°„é…ç½®ï¼Œä½¿ç”¨åŸå§‹åç¨±
                    (requested_model.clone(), requested_model)
                }
            } else {
                // å®Œå…¨æ²’æœ‰ç›¸é—œé…ç½®ï¼Œä½¿ç”¨åŸå§‹åç¨±
                (requested_model.clone(), requested_model)
            }
        }
    } else {
        // é…ç½®æœªå•Ÿç”¨ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹åç¨±
        (chat_request.model.clone(), chat_request.model.clone())
    };
    info!("ğŸ¤– ä½¿ç”¨æ¨¡å‹: {} (åŸå§‹: {})", display_model, original_model);

    // å‰µå»ºå®¢æˆ¶ç«¯
    let client = PoeClientWrapper::new(&original_model, &access_key);

    // è™•ç†æ¶ˆæ¯ä¸­çš„image_url
    let mut messages = chat_request.messages.clone();
    if let Err(e) = process_message_images(&client, &mut messages).await {
        error!("âŒ è™•ç†æ–‡ä»¶ä¸Šå‚³å¤±æ•—: {}", e);
        res.status_code(StatusCode::INTERNAL_SERVER_ERROR);
        res.render(Json(OpenAIErrorResponse {
            error: OpenAIError {
                message: format!("è™•ç†æ–‡ä»¶ä¸Šå‚³å¤±æ•—: {}", e),
                r#type: "processing_error".to_string(),
                code: "file_processing_failed".to_string(),
                param: None,
            },
        }));
        return;
    }

    // è¨ˆç®— prompt_tokens
    let prompt_tokens = count_message_tokens(&messages);
    debug!("ğŸ“Š è¨ˆç®— prompt_tokens: {}", prompt_tokens);

    let stream = chat_request.stream.unwrap_or(false);
    debug!("ğŸ”„ è«‹æ±‚æ¨¡å¼: {}", if stream { "ä¸²æµ" } else { "éä¸²æµ" });

    // å‰µå»º chat è«‹æ±‚
    let chat_request_obj = create_chat_request(
        &original_model,
        &chat_request,
    )
    .await;

    // æª¢æŸ¥æ˜¯å¦éœ€è¦åŒ…å« usage çµ±è¨ˆ
    let include_usage = chat_request
        .stream_options
        .as_ref()
        .and_then(|opts| opts.include_usage)
        .unwrap_or(false);
    debug!("ğŸ“Š æ˜¯å¦åŒ…å« usage çµ±è¨ˆ: {}", include_usage);

    // å‰µå»ºè¼¸å‡ºç”Ÿæˆå™¨
    let output_generator =
        OutputGenerator::new(display_model.clone(), prompt_tokens, include_usage);

    match client.stream_request(chat_request_obj).await {
        Ok(mut event_stream) => {
            let first_event = event_stream.next().await;

            if let Some(Ok(ChatResponse {
                event: ChatEventType::Error,
                data: Some(ChatResponseData::Error { text, allow_retry }),
            })) = &first_event
            {
                let insufficient_points_msg_1 =
                    "This bot needs more points to answer your request.";
                let insufficient_points_msg_2 =
                    "You do not have enough points to message this bot.";

                if text.contains(insufficient_points_msg_1)
                    || text.contains(insufficient_points_msg_2)
                {
                    info!("ğŸš« åµæ¸¬åˆ° Poe é»æ•¸ä¸è¶³éŒ¯èª¤ï¼Œè¿”å› 429 ç‹€æ…‹ç¢¼ã€‚");
                    let status = StatusCode::TOO_MANY_REQUESTS;
                    let body = OpenAIErrorResponse {
                        error: OpenAIError {
                            message: "You have exceeded your message quota for this model. Please try again later.".to_string(),
                            r#type: "insufficient_quota".to_string(),
                            code: "insufficient_quota".to_string(),
                            param: None,
                        },
                    };
                    res.status_code(status);
                    res.render(Json(body));
                    return;
                } else {
                    let (status, body) = convert_poe_error_to_openai(text, *allow_retry);
                    res.status_code(status);
                    res.render(Json(body));
                    return;
                }
            }

            let reconstituted_stream: Pin<
                Box<dyn Stream<Item = Result<ChatResponse, PoeError>> + Send>,
            > = if let Some(first) = first_event {
                Box::pin(stream::once(async { first }).chain(event_stream))
            } else {
                Box::pin(stream::empty())
            };

            if stream {
                handle_stream_response(res, reconstituted_stream, output_generator).await;
            } else {
                handle_non_stream_response(res, reconstituted_stream, output_generator).await;
            }
        }
        Err(e) => {
            error!("âŒ å»ºç«‹ä¸²æµè«‹æ±‚å¤±æ•—: {}", e);
            res.status_code(StatusCode::INTERNAL_SERVER_ERROR);
            res.render(Json(json!({ "error": e.to_string() })));
        }
    }

    let duration = start_time.elapsed();
    info!("âœ… è«‹æ±‚è™•ç†å®Œæˆ | è€—æ™‚: {}", format_duration(duration));
}

// è™•ç†ä¸²æµéŸ¿æ‡‰
async fn handle_stream_response(
    res: &mut Response,
    event_stream: Pin<Box<dyn Stream<Item = Result<ChatResponse, PoeError>> + Send>>,
    output_generator: OutputGenerator,
) {
    let start_time = Instant::now();
    let id = output_generator.id.clone();
    let model = output_generator.model.clone();
    let include_usage = output_generator.include_usage;
    info!(
        "ğŸŒŠ é–‹å§‹è™•ç†ä¸²æµéŸ¿æ‡‰ | ID: {} | æ¨¡å‹: {} | åŒ…å«ä½¿ç”¨çµ±è¨ˆ: {}",
        id, model, include_usage
    );

    // è¨­ç½®ä¸²æµéŸ¿æ‡‰çš„é ­éƒ¨
    res.headers_mut()
        .insert(header::CONTENT_TYPE, "text/event-stream".parse().unwrap());
    res.headers_mut()
        .insert(header::CACHE_CONTROL, "no-cache".parse().unwrap());
    res.headers_mut()
        .insert(header::CONNECTION, "keep-alive".parse().unwrap());

    // è™•ç†äº‹ä»¶æµä¸¦ç”Ÿæˆè¼¸å‡º
    let processed_stream = output_generator
        .process_stream(Box::pin(event_stream))
        .await;
    res.stream(processed_stream);

    let duration = start_time.elapsed();
    info!(
        "âœ… ä¸²æµéŸ¿æ‡‰è™•ç†å®Œæˆ | ID: {} | è€—æ™‚: {}",
        id,
        format_duration(duration)
    );
}

// è™•ç†éä¸²æµéŸ¿æ‡‰
async fn handle_non_stream_response(
    res: &mut Response,
    mut event_stream: Pin<Box<dyn Stream<Item = Result<ChatResponse, PoeError>> + Send>>,
    output_generator: OutputGenerator,
) {
    let start_time = Instant::now();
    let id = output_generator.id.clone();
    let model = output_generator.model.clone();
    let include_usage = output_generator.include_usage;
    info!(
        "ğŸ“¦ é–‹å§‹è™•ç†éä¸²æµéŸ¿æ‡‰ | ID: {} | æ¨¡å‹: {} | åŒ…å«ä½¿ç”¨çµ±è¨ˆ: {}",
        id, model, include_usage
    );

    let handler_manager = EventHandlerManager::new();
    let mut ctx = EventContext::default();

    // è™•ç†æ‰€æœ‰äº‹ä»¶
    while let Some(result) = event_stream.next().await {
        match result {
            Ok(event) => {
                handler_manager.handle(&event, &mut ctx);
                // æª¢æŸ¥æ˜¯å¦æœ‰éŒ¯èª¤
                if let Some((status, error_response)) = &ctx.error {
                    error!("âŒ è™•ç†éŒ¯èª¤: {:?}", error_response);
                    res.status_code(*status);
                    res.render(Json(error_response));
                    return;
                }
                // æª¢æŸ¥æ˜¯å¦å®Œæˆ
                if ctx.done {
                    debug!("âœ… æ”¶åˆ°å®Œæˆäº‹ä»¶");
                    break;
                }
            }
            Err(e) => {
                error!("âŒ è™•ç†éŒ¯èª¤: {}", e);
                let (status, error_response) = convert_poe_error_to_openai(&e.to_string(), false);
                res.status_code(status);
                res.render(Json(error_response));
                return;
            }
        }
    }

    // å‰µå»ºæœ€çµ‚éŸ¿æ‡‰
    let response = output_generator.create_final_response(&mut ctx);
    res.render(Json(response));

    let duration = start_time.elapsed();
    info!(
        "âœ… éä¸²æµéŸ¿æ‡‰è™•ç†å®Œæˆ | ID: {} | è€—æ™‚: {}",
        id,
        format_duration(duration)
    );
}

// è¼¸å‡ºç”Ÿæˆå™¨ - ç”¨æ–¼å°‡ EventContext è½‰æ›ç‚ºæœ€çµ‚è¼¸å‡º
#[derive(Clone)]
struct OutputGenerator {
    id: String,
    created: i64,
    model: String,
    prompt_tokens: u32,
    include_usage: bool,
}

impl OutputGenerator {
    fn new(model: String, prompt_tokens: u32, include_usage: bool) -> Self {
        Self {
            id: nanoid!(10),
            created: Utc::now().timestamp(),
            model,
            prompt_tokens,
            include_usage,
        }
    }

    // è™•ç†æ–‡ä»¶å¼•ç”¨ï¼Œå°‡ [ref_id] æ›¿æ›ç‚º (url)
    fn process_file_references(
        &self,
        content: &str,
        file_refs: &HashMap<String, poe_api_process::types::FileData>,
    ) -> String {
        if file_refs.is_empty() {
            return content.to_string();
        }
        let mut processed = content.to_string();
        let mut has_replaced = false;

        for (ref_id, file_data) in file_refs {
            let img_marker = format!("[{}]", ref_id);
            if processed.contains(&img_marker) {
                let replacement = format!("({})", file_data.url);
                processed = processed.replace(&img_marker, &replacement);
                debug!("ğŸ–¼ï¸ æ›¿æ›åœ–ç‰‡å¼•ç”¨ | ID: {} | URL: {}", ref_id, file_data.url);
                has_replaced = true;
            }
        }

        if has_replaced {
            debug!("âœ… æˆåŠŸæ›¿æ›åœ–ç‰‡å¼•ç”¨");
        } else if processed.contains('[') && processed.contains(']') {
            warn!(
                "âš ï¸ æ–‡æœ¬åŒ…å«å¯èƒ½çš„åœ–ç‰‡å¼•ç”¨æ ¼å¼ï¼Œä½†æœªæ‰¾åˆ°å°æ‡‰å¼•ç”¨: {}",
                processed
            );
        }

        processed
    }

    // è¨ˆç®— token ä½¿ç”¨æƒ…æ³
    fn calculate_tokens(&self, ctx: &mut EventContext) -> (u32, u32, u32) {
        let content = match &ctx.replace_buffer {
            Some(replace_content) => replace_content,
            None => &ctx.content,
        };
        let completion_tokens = count_completion_tokens(content);
        ctx.completion_tokens = completion_tokens;
        let total_tokens = self.prompt_tokens + completion_tokens;
        (self.prompt_tokens, completion_tokens, total_tokens)
    }

    // å‰µå»ºè§’è‰² chunk
    // å‰µå»ºè§’è‰² chunk
    fn create_role_chunk(&self) -> ChatCompletionChunk {
        let role_delta = Delta {
            role: Some("assistant".to_string()),
            content: None,
            refusal: None,
            tool_calls: None,
            reasoning_content: None,
        };
        ChatCompletionChunk {
            id: format!("chatcmpl-{}", self.id),
            object: "chat.completion.chunk".to_string(),
            created: self.created,
            model: self.model.clone(),
            choices: vec![Choice {
                index: 0,
                delta: role_delta,
                finish_reason: None,
            }],
        }
    }

    // æ€è€ƒ chunk
    fn create_reasoning_chunk(&self, reasoning_content: &str) -> ChatCompletionChunk {
        let reasoning_delta = Delta {
            role: None,
            content: None,
            refusal: None,
            tool_calls: None,
            reasoning_content: Some(reasoning_content.to_string()),
        };
        ChatCompletionChunk {
            id: format!("chatcmpl-{}", self.id),
            object: "chat.completion.chunk".to_string(),
            created: self.created,
            model: self.model.clone(),
            choices: vec![Choice {
                index: 0,
                delta: reasoning_delta,
                finish_reason: None,
            }],
        }
    }
    // å‰µå»ºä¸²æµ chunk
    fn create_stream_chunk(
        &self,
        content: &str,
        finish_reason: Option<String>,
    ) -> ChatCompletionChunk {
        let mut delta = Delta {
            role: None,
            content: None,
            refusal: None,
            tool_calls: None,
            reasoning_content: None,
        };
        delta.content = Some(content.to_string());
        debug!(
            "ğŸ”§ å‰µå»ºä¸²æµç‰‡æ®µ | ID: {} | å…§å®¹é•·åº¦: {}",
            self.id,
            format_bytes_length(content.len())
        );
        ChatCompletionChunk {
            id: format!("chatcmpl-{}", self.id),
            object: "chat.completion.chunk".to_string(),
            created: self.created,
            model: self.model.clone(),
            choices: vec![Choice {
                index: 0,
                delta,
                finish_reason,
            }],
        }
    }

    // å‰µå»ºå·¥å…·èª¿ç”¨ chunk
    fn create_tool_calls_chunk(
        &self,
        tool_calls: &[poe_api_process::types::ChatToolCall],
    ) -> ChatCompletionChunk {
        let tool_delta = Delta {
            role: None,
            content: None,
            refusal: None,
            tool_calls: Some(tool_calls.to_vec()),
            reasoning_content: None,
        };
        ChatCompletionChunk {
            id: format!("chatcmpl-{}", self.id),
            object: "chat.completion.chunk".to_string(),
            created: self.created,
            model: self.model.clone(),
            choices: vec![Choice {
                index: 0,
                delta: tool_delta,
                finish_reason: Some("tool_calls".to_string()),
            }],
        }
    }

    // å‰µå»ºæœ€çµ‚å®Œæ•´å›æ‡‰ï¼ˆéä¸²æµæ¨¡å¼ï¼‰
    fn create_final_response(&self, ctx: &mut EventContext) -> ChatCompletionResponse {
        // è™•ç†å‰©é¤˜çš„ pending_text
        if !ctx.pending_text.trim().is_empty() {
            use crate::evert::ThinkingProcessor;
            let (reasoning_output, content_output) = ThinkingProcessor::process_text_chunk(ctx, "");
            if let Some(final_reasoning) = reasoning_output {
                ctx.reasoning_content.push_str(&final_reasoning);
            }
            if let Some(final_content) = content_output {
                ctx.content.push_str(&final_content);
            }
        }

        // è™•ç†å…§å®¹ï¼ŒåŒ…æ‹¬æ–‡ä»¶å¼•ç”¨æ›¿æ›
        let content = if let Some(replace_content) = &ctx.replace_buffer {
            self.process_file_references(replace_content, &ctx.file_refs)
        } else {
            self.process_file_references(&ctx.content, &ctx.file_refs)
        };

        // è¨ˆç®— token
        let (prompt_tokens, completion_tokens, total_tokens) = self.calculate_tokens(ctx);

        // ç¢ºå®š finish_reason
        let finish_reason = if !ctx.tool_calls.is_empty() {
            "tool_calls".to_string()
        } else {
            "stop".to_string()
        };

        debug!(
            "ğŸ“¤ æº–å‚™ç™¼é€å›æ‡‰ | å…§å®¹é•·åº¦: {} | æ€è€ƒé•·åº¦: {} | å·¥å…·èª¿ç”¨æ•¸é‡: {} | å®ŒæˆåŸå› : {}",
            format_bytes_length(content.len()),
            format_bytes_length(ctx.reasoning_content.len()),
            ctx.tool_calls.len(),
            finish_reason
        );

        // å‰µå»ºéŸ¿æ‡‰
        let mut response = ChatCompletionResponse {
            id: format!("chatcmpl-{}", self.id),
            object: "chat.completion".to_string(),
            created: self.created,
            model: self.model.clone(),
            choices: vec![CompletionChoice {
                index: 0,
                message: CompletionMessage {
                    role: "assistant".to_string(),
                    content,
                    refusal: None,
                    tool_calls: if ctx.tool_calls.is_empty() {
                        None
                    } else {
                        Some(ctx.tool_calls.clone())
                    },
                    reasoning_content: if ctx.reasoning_content.trim().is_empty() {
                        None
                    } else {
                        Some(ctx.reasoning_content.clone())
                    },
                },
                logprobs: None,
                finish_reason: Some(finish_reason),
            }],
            usage: None,
        };

        if self.include_usage {
            response.usage = Some(serde_json::json!({
                "prompt_tokens": prompt_tokens,
                "completion_tokens": completion_tokens,
                "total_tokens": total_tokens,
                "prompt_tokens_details": {"cached_tokens": 0}
            }));
        }

        response
    }

    // ç›´æ¥è™•ç†ä¸²æµäº‹ä»¶ä¸¦ç”¢ç”Ÿè¼¸å‡ºï¼Œç„¡éœ€é è®€
    pub async fn process_stream<S>(
        self,
        event_stream: S,
    ) -> impl Stream<Item = Result<String, std::convert::Infallible>> + Send + 'static
    where
        S: Stream<Item = Result<ChatResponse, PoeError>> + Send + Unpin + 'static,
    {
        let ctx = Arc::new(Mutex::new(EventContext::default()));
        let handler_manager = EventHandlerManager::new();

        // ç›´æ¥ç”¨ unfold é‚è¼¯è™•ç†äº‹ä»¶æµ
        let stream_processor = stream::unfold(
            (event_stream, false, ctx, handler_manager, self),
            move |(mut event_stream, mut is_done, ctx_arc, handler_manager, generator)| {
                let ctx_arc_clone = Arc::clone(&ctx_arc);
                async move {
                    if is_done {
                        debug!("âœ… ä¸²æµè™•ç†å®Œæˆ");
                        return None;
                    }

                    match event_stream.next().await {
                        Some(Ok(event)) => {
                            // é–å®šä¸Šä¸‹æ–‡ä¸¦è™•ç†äº‹ä»¶
                            let mut output_content: Option<String> = None;
                            {
                                let mut ctx_guard = ctx_arc_clone.lock().unwrap();

                                // è™•ç†äº‹ä»¶ä¸¦ç²å–è¦ç™¼é€çš„å…§å®¹
                                let chunk_content_opt =
                                    handler_manager.handle(&event, &mut ctx_guard);

                                // æª¢æŸ¥éŒ¯èª¤
                                if let Some((_, error_response)) = &ctx_guard.error {
                                    debug!("âŒ æª¢æ¸¬åˆ°éŒ¯èª¤ï¼Œä¸­æ–·ä¸²æµ");
                                    let error_json = serde_json::to_string(error_response).unwrap();
                                    return Some((
                                        Ok(format!("data: {}\n\n", error_json)),
                                        (event_stream, true, ctx_arc, handler_manager, generator),
                                    ));
                                }

                                // æª¢æŸ¥æ˜¯å¦å®Œæˆ
                                if ctx_guard.done {
                                    debug!("âœ… æª¢æ¸¬åˆ°å®Œæˆä¿¡è™Ÿ");
                                    is_done = true;
                                }

                                // è™•ç†è¿”å›çš„å…§å®¹
                                match event.event {
                                    ChatEventType::Text => {
                                        if let Some(chunk_content) = chunk_content_opt {
                                            debug!("ğŸ“ è™•ç†æ™®é€š Text äº‹ä»¶");

                                            // æª¢æŸ¥æ˜¯å¦æ˜¯æ€è€ƒå…§å®¹æª¢æ¸¬æ¨™è¨˜
                                            if chunk_content == "__REASONING_DETECTED__" {
                                                debug!("ğŸ§  æª¢æ¸¬åˆ°æ€è€ƒå…§å®¹ï¼Œæº–å‚™ç™¼é€æ€è€ƒç‰‡æ®µ");

                                                // ç²å–æœ€æ–°çš„æ€è€ƒå…§å®¹ï¼ˆå¾ä¸Šæ¬¡ç™¼é€å¾Œçš„æ–°å¢éƒ¨åˆ†ï¼‰
                                                let current_reasoning_len =
                                                    ctx_guard.reasoning_content.len();
                                                let last_sent_reasoning_len = ctx_guard
                                                    .get("last_sent_reasoning_len")
                                                    .unwrap_or(0);

                                                if current_reasoning_len > last_sent_reasoning_len {
                                                    let new_reasoning = ctx_guard.reasoning_content
                                                        [last_sent_reasoning_len..]
                                                        .to_string();

                                                    if !new_reasoning.trim().is_empty() {
                                                        // æ›´æ–°å·²ç™¼é€çš„æ€è€ƒå…§å®¹é•·åº¦
                                                        ctx_guard.insert(
                                                            "last_sent_reasoning_len",
                                                            current_reasoning_len,
                                                        );

                                                        // ç™¼é€è§’è‰²å¡Šï¼ˆå¦‚æœé‚„æ²’ç™¼é€ï¼‰
                                                        let mut output_parts = Vec::new();

                                                        if !ctx_guard.role_chunk_sent {
                                                            let role_chunk =
                                                                generator.create_role_chunk();
                                                            let role_json =
                                                                serde_json::to_string(&role_chunk)
                                                                    .unwrap();
                                                            output_parts.push(format!(
                                                                "data: {}",
                                                                role_json
                                                            ));
                                                            ctx_guard.role_chunk_sent = true;
                                                        }

                                                        // ç™¼é€æ€è€ƒå…§å®¹
                                                        let reasoning_chunk = generator
                                                            .create_reasoning_chunk(&new_reasoning);
                                                        let reasoning_json =
                                                            serde_json::to_string(&reasoning_chunk)
                                                                .unwrap();
                                                        output_parts.push(format!(
                                                            "data: {}",
                                                            reasoning_json
                                                        ));

                                                        let output =
                                                            output_parts.join("\n\n") + "\n\n";
                                                        debug!(
                                                            "ğŸ§  ç™¼é€æ€è€ƒç‰‡æ®µ | é•·åº¦: {}",
                                                            format_bytes_length(output.len())
                                                        );

                                                        output_content = Some(output);
                                                    }
                                                }
                                            } else {
                                                // æ­£å¸¸å…§å®¹è™•ç†
                                                let processed = generator.process_file_references(
                                                    &chunk_content,
                                                    &ctx_guard.file_refs,
                                                );

                                                // åˆ¤æ–·æ˜¯å¦éœ€è¦ç™¼é€è§’è‰²å¡Š
                                                if !ctx_guard.role_chunk_sent {
                                                    let role_chunk = generator.create_role_chunk();
                                                    let role_json =
                                                        serde_json::to_string(&role_chunk).unwrap();
                                                    ctx_guard.role_chunk_sent = true;

                                                    let content_chunk = generator
                                                        .create_stream_chunk(&processed, None);
                                                    let content_json =
                                                        serde_json::to_string(&content_chunk)
                                                            .unwrap();

                                                    output_content = Some(format!(
                                                        "data: {}\n\ndata: {}\n\n",
                                                        role_json, content_json
                                                    ));
                                                } else {
                                                    let chunk = generator
                                                        .create_stream_chunk(&processed, None);
                                                    let json =
                                                        serde_json::to_string(&chunk).unwrap();
                                                    output_content =
                                                        Some(format!("data: {}\n\n", json));
                                                }
                                            }
                                        }
                                    }
                                    ChatEventType::File => {
                                        // è™•ç†æ–‡ä»¶äº‹ä»¶ï¼Œå¦‚æœè¿”å›äº†å…§å®¹ï¼Œè¡¨ç¤ºæœ‰åœ–ç‰‡å¼•ç”¨éœ€è¦ç«‹å³è™•ç†
                                        if let Some(chunk_content) = chunk_content_opt {
                                            debug!("ğŸ–¼ï¸ è™•ç†æª”æ¡ˆå¼•ç”¨ï¼Œç”¢ç”ŸåŒ…å«URLçš„è¼¸å‡º");

                                            // åˆ¤æ–·æ˜¯å¦éœ€è¦ç™¼é€è§’è‰²å¡Š
                                            if !ctx_guard.role_chunk_sent {
                                                let role_chunk = generator.create_role_chunk();
                                                let role_json =
                                                    serde_json::to_string(&role_chunk).unwrap();
                                                ctx_guard.role_chunk_sent = true;

                                                let content_chunk = generator
                                                    .create_stream_chunk(&chunk_content, None);
                                                let content_json =
                                                    serde_json::to_string(&content_chunk).unwrap();

                                                output_content = Some(format!(
                                                    "data: {}\n\ndata: {}\n\n",
                                                    role_json, content_json
                                                ));
                                            } else {
                                                let chunk = generator
                                                    .create_stream_chunk(&chunk_content, None);
                                                let json = serde_json::to_string(&chunk).unwrap();
                                                output_content =
                                                    Some(format!("data: {}\n\n", json));
                                            }
                                        }
                                    }
                                    ChatEventType::ReplaceResponse => {
                                        // å¦‚æœ ReplaceResponse ç›´æ¥è¿”å›äº†å…§å®¹ï¼Œèªªæ˜å…¶ä¸­åŒ…å«äº†åœ–ç‰‡å¼•ç”¨
                                        if let Some(chunk_content) = chunk_content_opt {
                                            debug!("ğŸ”„ ReplaceResponse åŒ…å«åœ–ç‰‡å¼•ç”¨ï¼Œç›´æ¥ç™¼é€");

                                            // åˆ¤æ–·æ˜¯å¦éœ€è¦ç™¼é€è§’è‰²å¡Š
                                            if !ctx_guard.role_chunk_sent {
                                                let role_chunk = generator.create_role_chunk();
                                                let role_json =
                                                    serde_json::to_string(&role_chunk).unwrap();
                                                ctx_guard.role_chunk_sent = true;

                                                let content_chunk = generator
                                                    .create_stream_chunk(&chunk_content, None);
                                                let content_json =
                                                    serde_json::to_string(&content_chunk).unwrap();

                                                output_content = Some(format!(
                                                    "data: {}\n\ndata: {}\n\n",
                                                    role_json, content_json
                                                ));
                                            } else {
                                                let chunk = generator
                                                    .create_stream_chunk(&chunk_content, None);
                                                let json = serde_json::to_string(&chunk).unwrap();
                                                output_content =
                                                    Some(format!("data: {}\n\n", json));
                                            }
                                        }
                                    }
                                    ChatEventType::Json => {
                                        if !ctx_guard.tool_calls.is_empty() {
                                            debug!("ğŸ”§ è™•ç†å·¥å…·èª¿ç”¨");
                                            let tool_chunk = generator
                                                .create_tool_calls_chunk(&ctx_guard.tool_calls);
                                            let json = serde_json::to_string(&tool_chunk).unwrap();

                                            if !ctx_guard.role_chunk_sent {
                                                let role_chunk = generator.create_role_chunk();
                                                let role_json =
                                                    serde_json::to_string(&role_chunk).unwrap();
                                                ctx_guard.role_chunk_sent = true;
                                                output_content = Some(format!(
                                                    "data: {}\n\ndata: {}\n\n",
                                                    role_json, json
                                                ));
                                            } else {
                                                output_content =
                                                    Some(format!("data: {}\n\n", json));
                                            }
                                        }
                                    }
                                    ChatEventType::Done => {
                                        // å¦‚æœ Done äº‹ä»¶è¿”å›äº†å…§å®¹ï¼Œè¡¨ç¤ºæœ‰æœªè™•ç†çš„åœ–ç‰‡å¼•ç”¨
                                        if let Some(chunk_content) = chunk_content_opt {
                                            if chunk_content != "done" && !ctx_guard.image_urls_sent
                                            {
                                                debug!(
                                                    "âœ… Done äº‹ä»¶åŒ…å«æœªè™•ç†çš„åœ–ç‰‡å¼•ç”¨ï¼Œç™¼é€æœ€çµ‚å…§å®¹"
                                                );
                                                let chunk = generator.create_stream_chunk(
                                                    &chunk_content,
                                                    Some("stop".to_string()),
                                                );
                                                let json = serde_json::to_string(&chunk).unwrap();
                                                output_content =
                                                    Some(format!("data: {}\n\n", json));
                                                ctx_guard.image_urls_sent = true; // æ¨™è¨˜å·²ç™¼é€
                                            } else {
                                                // ä¸€èˆ¬å®Œæˆäº‹ä»¶
                                                let (
                                                    prompt_tokens,
                                                    completion_tokens,
                                                    total_tokens,
                                                ) = generator.calculate_tokens(&mut ctx_guard);
                                                let finish_reason =
                                                    if !ctx_guard.tool_calls.is_empty() {
                                                        "tool_calls"
                                                    } else {
                                                        "stop"
                                                    };
                                                let final_chunk = generator.create_stream_chunk(
                                                    "",
                                                    Some(finish_reason.to_string()),
                                                );
                                                let final_json = if generator.include_usage {
                                                    debug!(
                                                        "ğŸ“Š Token ä½¿ç”¨çµ±è¨ˆ | prompt_tokens: {} | completion_tokens: {} | total_tokens: {}",
                                                        prompt_tokens,
                                                        completion_tokens,
                                                        total_tokens
                                                    );
                                                    let mut json_value =
                                                        serde_json::to_value(&final_chunk).unwrap();
                                                    json_value["usage"] = serde_json::json!({
                                                        "prompt_tokens": prompt_tokens,
                                                        "completion_tokens": completion_tokens,
                                                        "total_tokens": total_tokens,
                                                        "prompt_tokens_details": {"cached_tokens": 0}
                                                    });
                                                    serde_json::to_string(&json_value).unwrap()
                                                } else {
                                                    serde_json::to_string(&final_chunk).unwrap()
                                                };

                                                if !ctx_guard.role_chunk_sent {
                                                    let role_chunk = generator.create_role_chunk();
                                                    let role_json =
                                                        serde_json::to_string(&role_chunk).unwrap();
                                                    ctx_guard.role_chunk_sent = true;
                                                    output_content = Some(format!(
                                                        "data: {}\n\ndata: {}\n\n",
                                                        role_json, final_json
                                                    ));
                                                } else {
                                                    output_content =
                                                        Some(format!("data: {}\n\n", final_json));
                                                }
                                            }
                                        } else {
                                            // ç„¡å…§å®¹çš„å®Œæˆäº‹ä»¶
                                            let (prompt_tokens, completion_tokens, total_tokens) =
                                                generator.calculate_tokens(&mut ctx_guard);
                                            let finish_reason = if !ctx_guard.tool_calls.is_empty()
                                            {
                                                "tool_calls"
                                            } else {
                                                "stop"
                                            };
                                            let final_chunk = generator.create_stream_chunk(
                                                "",
                                                Some(finish_reason.to_string()),
                                            );
                                            let final_json = if generator.include_usage {
                                                debug!(
                                                    "ğŸ“Š Token ä½¿ç”¨çµ±è¨ˆ | prompt_tokens: {} | completion_tokens: {} | total_tokens: {}",
                                                    prompt_tokens, completion_tokens, total_tokens
                                                );
                                                let mut json_value =
                                                    serde_json::to_value(&final_chunk).unwrap();
                                                json_value["usage"] = serde_json::json!({
                                                    "prompt_tokens": prompt_tokens,
                                                    "completion_tokens": completion_tokens,
                                                    "total_tokens": total_tokens,
                                                    "prompt_tokens_details": {"cached_tokens": 0}
                                                });
                                                serde_json::to_string(&json_value).unwrap()
                                            } else {
                                                serde_json::to_string(&final_chunk).unwrap()
                                            };

                                            if !ctx_guard.role_chunk_sent {
                                                let role_chunk = generator.create_role_chunk();
                                                let role_json =
                                                    serde_json::to_string(&role_chunk).unwrap();
                                                ctx_guard.role_chunk_sent = true;
                                                output_content = Some(format!(
                                                    "data: {}\n\ndata: {}\n\n",
                                                    role_json, final_json
                                                ));
                                            } else {
                                                output_content =
                                                    Some(format!("data: {}\n\n", final_json));
                                            }
                                        }
                                    }
                                    _ => {
                                        // å…¶ä»–äº‹ä»¶é¡å‹ï¼Œå¦‚æœæœ‰è¿”å›å…§å®¹ä¹Ÿè™•ç†
                                        if let Some(chunk_content) = chunk_content_opt {
                                            if !ctx_guard.role_chunk_sent {
                                                let role_chunk = generator.create_role_chunk();
                                                let role_json =
                                                    serde_json::to_string(&role_chunk).unwrap();
                                                ctx_guard.role_chunk_sent = true;

                                                let content_chunk = generator
                                                    .create_stream_chunk(&chunk_content, None);
                                                let content_json =
                                                    serde_json::to_string(&content_chunk).unwrap();

                                                output_content = Some(format!(
                                                    "data: {}\n\ndata: {}\n\n",
                                                    role_json, content_json
                                                ));
                                            } else {
                                                let chunk = generator
                                                    .create_stream_chunk(&chunk_content, None);
                                                let json = serde_json::to_string(&chunk).unwrap();
                                                output_content =
                                                    Some(format!("data: {}\n\n", json));
                                            }
                                        }
                                    }
                                }

                                // å¦‚æœæ²’æœ‰è¼¸å‡ºå…§å®¹ä¸”éœ€è¦ç™¼é€è§’è‰²å¡Šï¼Œå‰‡ç™¼é€
                                if output_content.is_none()
                                    && !ctx_guard.role_chunk_sent
                                    && (event.event == ChatEventType::Text
                                        || event.event == ChatEventType::ReplaceResponse
                                        || event.event == ChatEventType::File)
                                {
                                    let role_chunk = generator.create_role_chunk();
                                    let role_json = serde_json::to_string(&role_chunk).unwrap();
                                    ctx_guard.role_chunk_sent = true;
                                    output_content = Some(format!("data: {}\n\n", role_json));
                                }
                            }

                            // è¿”å›è¼¸å‡ºå…§å®¹
                            if let Some(output) = output_content {
                                if !output.trim().is_empty() {
                                    debug!(
                                        "ğŸ“¤ ç™¼é€ä¸²æµç‰‡æ®µ | é•·åº¦: {}",
                                        format_bytes_length(output.len())
                                    );
                                    Some((
                                        Ok(output),
                                        (
                                            event_stream,
                                            is_done,
                                            ctx_arc,
                                            handler_manager,
                                            generator,
                                        ),
                                    ))
                                } else {
                                    // ç©ºè¼¸å‡ºï¼Œç¹¼çºŒè™•ç†
                                    Some((
                                        Ok(String::new()),
                                        (
                                            event_stream,
                                            is_done,
                                            ctx_arc,
                                            handler_manager,
                                            generator,
                                        ),
                                    ))
                                }
                            } else {
                                // æ²’æœ‰è¼¸å‡ºï¼Œä½†ç¹¼çºŒè™•ç†
                                Some((
                                    Ok(String::new()),
                                    (event_stream, is_done, ctx_arc, handler_manager, generator),
                                ))
                            }
                        }
                        Some(Err(e)) => {
                            error!("âŒ ä¸²æµè™•ç†éŒ¯èª¤: {}", e);
                            let error_response = convert_poe_error_to_openai(&e.to_string(), false);
                            let error_json = serde_json::to_string(&error_response.1).unwrap();
                            Some((
                                Ok(format!("data: {}\n\n", error_json)),
                                (event_stream, true, ctx_arc, handler_manager, generator),
                            ))
                        }
                        None => {
                            debug!("â¹ï¸ äº‹ä»¶æµçµæŸ");
                            None
                        }
                    }
                }
            },
        );

        // æ·»åŠ çµæŸæ¶ˆæ¯
        let done_message = "data: [DONE]\n\n".to_string();

        // éæ¿¾æ‰ç©ºçš„è¨Šæ¯ï¼Œä¸¦åŠ ä¸ŠçµæŸè¨Šæ¯
        Box::pin(
            stream_processor
                .filter(|result| {
                    future::ready(match result {
                        Ok(s) => !s.is_empty(),
                        Err(_) => true,
                    })
                })
                .chain(stream::once(future::ready(Ok(done_message)))),
        )
    }
}
